# vLLM Deployment Assistant Skill - Project Structure

```
vllm-skills/
â”‚
â”œâ”€â”€ README.md                           # Main project documentation
â”œâ”€â”€ USAGE_GUIDE.md                      # Comprehensive usage guide
â”œâ”€â”€ .gitignore                          # Git ignore rules
â”‚
â”œâ”€â”€ examples/                           # Usage examples
â”‚   â””â”€â”€ deployment_example.py           # Complete working example
â”‚
â””â”€â”€ vllm_skills/                        # Main Python package
    â”œâ”€â”€ __init__.py                     # Package root
    â”‚
    â””â”€â”€ library/                        # Skills library
        â”œâ”€â”€ __init__.py
        â”‚
        â””â”€â”€ deployment/                 # ğŸ¯ DEPLOYMENT ASSISTANT SKILL
            â”‚
            â”œâ”€â”€ SKILL.md                # ğŸ“˜ Complete skill definition (13.7KB)
            â”‚                           #    - Metadata & requirements
            â”‚                           #    - Environment detection checklist
            â”‚                           #    - Configuration parameters
            â”‚                           #    - Recipe integration
            â”‚                           #    - Troubleshooting flowcharts
            â”‚                           #    - Usage examples
            â”‚                           #    - Agent behavior guidelines
            â”‚
            â”œâ”€â”€ __init__.py             # ğŸ”§ DeploymentAssistant class (16.3KB)
            â”‚                           #    - check_hardware()
            â”‚                           #    - check_environment()
            â”‚                           #    - find_recipe()
            â”‚                           #    - suggest_config()
            â”‚                           #    - generate_command()
            â”‚
            â”œâ”€â”€ checks/                 # ğŸ” System detection modules
            â”‚   â”œâ”€â”€ __init__.py
            â”‚   â”œâ”€â”€ hardware.py         #    - GPU/CPU/RAM detection
            â”‚   â”œâ”€â”€ environment.py      #    - Python/CUDA/PyTorch/vLLM versions
            â”‚   â””â”€â”€ compatibility.py    #    - Version compatibility matrix
            â”‚
            â”œâ”€â”€ config/                 # âš™ï¸ Configuration management
            â”‚   â”œâ”€â”€ __init__.py
            â”‚   â”œâ”€â”€ parameters.py       #    - Parameter descriptions & validation
            â”‚   â”‚
            â”‚   â””â”€â”€ presets/            # ğŸ“‹ Pre-configured setups
            â”‚       â”œâ”€â”€ high_throughput.yaml      # Max batch size
            â”‚       â”œâ”€â”€ low_latency.yaml          # Min response time
            â”‚       â””â”€â”€ memory_constrained.yaml   # Limited VRAM
            â”‚
            â”œâ”€â”€ models/                 # ğŸ“Š Model information
            â”‚   â”œâ”€â”€ recipe_index.yaml   #    - 25+ models â†’ vllm-project/recipes
            â”‚   â”‚                       #    - DeepSeek, Qwen, Llama, Mistral, etc.
            â”‚   â”‚
            â”‚   â””â”€â”€ hardware_matrix.yaml#    - GPU requirements by model size
            â”‚                           #    - 1B-3B, 7B-8B, 13B-14B, 70B-72B, 405B+
            â”‚                           #    - MoE models, quantization savings
            â”‚
            â”œâ”€â”€ troubleshooting/        # ğŸ”§ Problem-solving guides
            â”‚   â”œâ”€â”€ common_issues.md    #    - Quick reference table (9.1KB)
            â”‚   â”‚                       #    - OOM, Flash Attention, Architecture
            â”‚   â”‚
            â”‚   â”œâ”€â”€ cuda_errors.md      #    - CUDA diagnostics (9.2KB)
            â”‚   â”‚                       #    - OOM, version mismatch, driver issues
            â”‚   â”‚                       #    - Runtime errors, kernel launches
            â”‚   â”‚
            â”‚   â”œâ”€â”€ memory_issues.md    #    - Memory optimization (10.3KB)
            â”‚   â”‚                       #    - OOM scenarios & solutions
            â”‚   â”‚                       #    - Quantization strategies
            â”‚   â”‚                       #    - Memory profiling
            â”‚   â”‚
            â”‚   â””â”€â”€ kernel_issues.md    #    - Kernel compilation (9.8KB)
            â”‚                           #    - Triton, Punica, Flash Attention
            â”‚                           #    - Compute capability issues
            â”‚
            â””â”€â”€ resources/              # ğŸ“š Reference materials
                â”œâ”€â”€ official_sources.yaml    # Official docs index (9.9KB)
                â”‚                           #    - vLLM documentation links
                â”‚                           #    - Recipes repository
                â”‚                           #    - GitHub resources
                â”‚                           #    - Community links
                â”‚
                â”œâ”€â”€ acceleration_libs.md    # Acceleration libraries (10.2KB)
                â”‚                           #    - Flash Attention 2
                â”‚                           #    - Triton
                â”‚                           #    - xFormers
                â”‚                           #    - cuBLAS/cuBLASLt
                â”‚                           #    - ROCm support
                â”‚
                â””â”€â”€ recipes_integration.md  # Using recipes (10.1KB)
                                            #    - Recipe structure
                                            #    - How to use recipes
                                            #    - Contributing recipes
```

## File Statistics

| Category | Files | Lines | Description |
|----------|-------|-------|-------------|
| **Core Skill** | 1 | 486 | SKILL.md - Agent instructions |
| **Python Implementation** | 7 | 836 | DeploymentAssistant + modules |
| **Configuration** | 4 | 260 | Presets & parameters |
| **Model Data** | 2 | 386 | Recipes & hardware matrix |
| **Troubleshooting** | 4 | 1,352 | Common issues guides |
| **Resources** | 3 | 1,074 | Official docs & libraries |
| **Documentation** | 2 | 519 | README & usage guide |
| **Examples** | 1 | 138 | Working example |
| **Total** | **24** | **5,051** | Complete skill package |

## Key Capabilities

### 1. Hardware Detection âœ…
- Automatically detects NVIDIA/AMD GPUs
- Reports VRAM, compute capability
- Detects CPU cores and system RAM
- Platform identification (NVIDIA/AMD/CPU)

### 2. Environment Detection âœ…
- Python version checking
- PyTorch + CUDA version detection
- vLLM installation verification
- Flash Attention, Triton, xFormers detection

### 3. Recipe Integration âœ…
- Maps 25+ models to deployment guides
- Links to vllm-project/recipes
- Model-specific configurations
- Known issues and workarounds

### 4. Configuration Generation âœ…
- Hardware-aware suggestions
- Use case optimization (throughput/latency/balanced)
- MoE model detection and configuration
- Quantization recommendations

### 5. Command Generation âœ…
- Builds complete vllm serve commands
- Includes all necessary flags
- Formatted for copy-paste
- Customizable configurations

### 6. Troubleshooting Support âœ…
- 4 comprehensive guides (38KB total)
- Systematic debugging flowcharts
- Common issues quick reference
- Solution-oriented documentation

## Usage Patterns

### For AI Agents
```python
# 1. Detect system
hardware = assistant.check_hardware()
env = assistant.check_environment()

# 2. Find recipe
recipe = assistant.find_recipe("model-name")

# 3. Generate config
config = assistant.suggest_config("model-name", hardware, "latency")

# 4. Build command
command = assistant.generate_command(config)
```

### For Users
```bash
# Run example to see capabilities
python examples/deployment_example.py

# Read skill definition
cat vllm_skills/library/deployment/SKILL.md

# Access troubleshooting
cat vllm_skills/library/deployment/troubleshooting/memory_issues.md
```

## Documentation Quality

- âœ… **Comprehensive**: Covers all aspects of vLLM deployment
- âœ… **Practical**: Copy-paste ready commands and solutions
- âœ… **Structured**: Organized by topic and use case
- âœ… **Maintained**: References to official docs and recipes
- âœ… **Tested**: Working Python implementation with examples

## Coverage

### Models (25+ recipes)
- DeepSeek (R1, V3, V3.1, V3.2)
- Qwen (Qwen3, Qwen2.5-VL, Qwen3-VL)
- Llama (3.1, 3.3, 4-Scout)
- Mistral (Large-3, Ministral-3, Mixtral)
- GLM (4, 4.5, 4.6, 4.7)
- NVIDIA Nemotron, Phi-4, Gemma-2, Command-R

### Issues Covered
- CUDA Out of Memory (OOM)
- CUDA version mismatches
- Flash Attention compatibility
- Kernel compilation failures
- Model architecture not supported
- Tensor parallel configuration
- Expert parallel (MoE models)
- Performance optimization

### Configurations
- Hardware: 1B-405B+ models
- GPUs: V100, A100, H100, RTX series, AMD
- Use cases: Throughput, Latency, Memory-constrained
- Features: Quantization, Caching, Chunked prefill

## Next Steps

This skill is ready for:
1. âœ… AI agent integration (Claude, GPT-4, etc.)
2. âœ… User-facing deployment assistance
3. âœ… Community contributions (more recipes, issues)
4. âœ… Extension with additional skills (monitoring, optimization, etc.)
